{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of hw1p2_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6m2eIB_WjuK"
      },
      "source": [
        "# Set up\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4oJkRd8Ohbs"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"yuzhongfinally\",\"key\":\"da5ea7094c4adb8f29251a2e3b240da7\"}\n",
        "with open('/content/gdrive/MyDrive/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 /content/gdrive/MyDrive/.kaggle/kaggle.json\n",
        "!cp /content/gdrive/MyDrive/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config set -n path -v /content/gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg7Xzth5WtOn"
      },
      "source": [
        "# Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke7la_R2YYHC"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XH_0e7El_2U"
      },
      "source": [
        "class Dataset_train(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, Y, offset , context ):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    index_map_X = []\n",
        "\n",
        "    for i, x in enumerate(X):\n",
        "      for j, xx in enumerate(x):\n",
        "        index_map_X.append((i, j))\n",
        "\n",
        "    self.index_map = index_map_X\n",
        "        \n",
        "    self.length = len(self.index_map)\n",
        "    self.context = context\n",
        "    self.offset = offset\n",
        "        \n",
        "    for i, x in enumerate(self.X):\n",
        "        self.X[i] = np.pad(x, ((context, context), (0, 0)), 'constant', constant_values=0)\n",
        "            \n",
        "        \n",
        "  def __len__(self):\n",
        "      \n",
        "      return self.length\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "      \n",
        "      i, j = self.index_map[index]\n",
        "      \n",
        "      start_j = j + self.offset - self.context\n",
        "      \n",
        "      end_j = j + self.offset + self.context + 1\n",
        "      \n",
        "      xx = self.X[i][start_j:end_j,:]\n",
        "\n",
        "      yy = self.Y[i][j]\n",
        "     \n",
        "      return xx ,yy  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDsJU27jvchm"
      },
      "source": [
        "def dataloader(data, label, offset, context, train_loader_args):\n",
        "  dataset = Dataset_train(data, label, offset, context)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset,**train_loader_args)\n",
        "                                        # collate_fn=Dataset_train.collate_fn)\n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btl4fGWoERek"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTE0X-Gjz_hm"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    # you can use the layer sizes as initialization arguments if you want to\n",
        "    def __init__(self,size_list):\n",
        "        super(MLP, self).__init__()\n",
        "        layers = []\n",
        "        self.size_list = size_list\n",
        "        for i in range(len(size_list) - 2):\n",
        "          \n",
        "          layers.append(nn.Linear(size_list[i], size_list[i+1]))\n",
        "          layers.append(nn.LeakyReLU())\n",
        "          layers.append(nn.BatchNorm1d(size_list[i+1]))\n",
        "          layers.append(nn.Dropout(0.3))\n",
        "          \n",
        "          \n",
        "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input_val):\n",
        " \n",
        "      return self.net(input_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emm0DF8oh-XI"
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "def train_parameters(model,criterion, iter, lr, data):\n",
        "\n",
        "  model.train()\n",
        "  #optimizer = torch.optim.SGD(model.parameters(),lr = 0.0005, momentum = 0.9)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr = lr, betas= (0.9, 0.99))\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=2.5e-6)\n",
        "  scheduler = StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
        "  \n",
        "  model = model.to(device= 'cuda')\n",
        "\n",
        "  for i in range(iter):\n",
        "    print('Epoch:',i)\n",
        "\n",
        "    avg_loss = 0.0\n",
        "    for batch_num,(X_train, y_train) in enumerate(data):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      X_train = X_train.to(device='cuda')\n",
        "      y_train = y_train.to(device='cuda')\n",
        "\n",
        "    \n",
        "      X_train = X_train.view(X_train.size(0), -1)\n",
        "      y_hat = model(X_train.float())\n",
        "\n",
        "      loss = criterion(y_hat, y_train.long())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      avg_loss += loss.item()\n",
        "      if batch_num % 99 == 1:\n",
        "          print('loss', avg_loss/100)\n",
        "          avg_loss = 0.0\n",
        "\n",
        "      del X_train\n",
        "      del y_train\n",
        "      del y_hat\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "\n",
        "    scheduler.step()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7hatLbCyrjO"
      },
      "source": [
        "# Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPlFE6oyL_Ig"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def model_val(net, dataloader_val):\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "\n",
        "    total_preds = []\n",
        "    truth = []\n",
        "    \n",
        "    for i,  (X_test, y_test) in enumerate(dataloader_val):\n",
        "      X_test = X_test.to(device='cuda')\n",
        "      X_test = X_test.view(X_test.size(0), -1)\n",
        "      y_test = y_test.to(device='cuda')\n",
        "       \n",
        "      \n",
        "      #output\n",
        "      output = net(X_test.float())\n",
        "      loss = criterion(output, y_test.long())\n",
        "\n",
        "      output = output.cpu()\n",
        "      y_test = y_test.cpu()\n",
        "      \n",
        "\n",
        "      output = output.detach().numpy()\n",
        "      true = y_test.numpy()\n",
        "      \n",
        "      output = np.argmax(output,axis = 1)\n",
        "      \n",
        "      #reshape\n",
        "      \n",
        "      true = true.reshape(-1,1)\n",
        "      output = output.reshape(-1,1)\n",
        "\n",
        "      total_preds.append(output)\n",
        "      truth.append(true)\n",
        "\n",
        "      del X_test\n",
        "      del y_test\n",
        "      del output\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      \n",
        "    \n",
        " \n",
        "  print('finished')\n",
        "  truth, total_preds = np.vstack(truth), np.vstack(total_preds)\n",
        "  acc = accuracy_score(truth, total_preds)\n",
        "  print(acc)\n",
        "  return acc, loss.item()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP7MJfPEMrGz"
      },
      "source": [
        "# run loop to find best parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyY5ZqFoxvxL"
      },
      "source": [
        "#tuning\n",
        "train = np.load('train.npy', allow_pickle = True)\n",
        "train_labels = np.load('train_labels.npy',allow_pickle = True)\n",
        "context = 25\n",
        "offset = 25\n",
        "batch_size = 64\n",
        "num_workers = 1\n",
        "\n",
        "train_loader_args = dict(shuffle = True, batch_size = batch_size, num_workers = num_workers) \n",
        "dataloader_train = dataloader(train,train_labels, offset, context, train_loader_args )\n",
        "\n",
        "del train\n",
        "del train_labels\n",
        "#!unzip dev.npy.zip\n",
        "#!unzip dev_labels.npy.zip\n",
        "dev = np.load('dev.npy', allow_pickle = True)\n",
        "dev_labels = np.load('dev_labels.npy',allow_pickle = True)\n",
        "dev_loader_args = dict(shuffle = True, batch_size = batch_size, num_workers =0)\n",
        "dataloader_val  = dataloader(dev,dev_labels, offset, context, dev_loader_args)\n",
        "del dev\n",
        "del dev_labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KWR_Kne7yiE",
        "outputId": "0274c7fe-5b5c-4cb1-f9f5-1c525b58e7bf"
      },
      "source": [
        "case_accuracy = model_val(model, dataloader_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished\n",
            "0.7447583128078817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBRgxG0lOmtA"
      },
      "source": [
        "# against learning rate\n",
        "lr = [0.1]\n",
        "#build the network\n",
        "\n",
        "context = 25\n",
        "input = (2 * int(context)+ 1) * 40\n",
        "output = 71\n",
        "\n",
        "hidden_lyr =[input,3550,3150, 2800, 2500,2000,2000,1650,1350,1000,650,output]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epoch =25\n",
        "report_lr = {}\n",
        "for l in lr:\n",
        "  #model = MLP(hidden_lyr)\n",
        "  model = torch.load('model1_0.72')\n",
        "  print(model)\n",
        "  accu_loss = train_parameters(model,criterion, epoch, l, dataloader_train)\n",
        "  case_accuracy = model_val(model, dataloader_val)\n",
        "  report_lr[l] = case_accuracy\n",
        "\n",
        "  if case_accuracy > 0.75:\n",
        "    torchname = \"model_lr_bn_\"+str(l)\n",
        "    torch.save(model, torchname)\n",
        "\n",
        "  print(report_lr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGcdrcAs06ic"
      },
      "source": [
        "# add Test set and submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3l0DEflCbkt"
      },
      "source": [
        "\n",
        "#!unzip test.npy.zip\n",
        "\n",
        "test = np.load('test.npy', allow_pickle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o5AwdnIdUOH"
      },
      "source": [
        "class load_test(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, X, offset, context):\n",
        "        \n",
        "        self.X = X\n",
        "        \n",
        "        index_map_X = []\n",
        "        \n",
        "        for i, x in enumerate(X):\n",
        "            for j, xx in enumerate(x):\n",
        "                index_pair_X = (i, j)\n",
        "                index_map_X.append(index_pair_X)\n",
        "                \n",
        "        self.index_map = index_map_X\n",
        "        \n",
        "        self.length = len(self.index_map)\n",
        "        \n",
        "        self.context = context\n",
        "        self.offset = offset\n",
        "\n",
        "        for i, x in enumerate(self.X):\n",
        "            self.X[i] = np.pad(x, ((context, context), (0, 0)), 'constant', constant_values=0)\n",
        "        \n",
        "    def __len__(self):\n",
        "\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        i, j = self.index_map[index]\n",
        "        \n",
        "        start_j = j + self.offset - self.context\n",
        "\n",
        "        end_j = j + self.offset + self.context + 1\n",
        "\n",
        "        xx = self.X[i][start_j:end_j,:]\n",
        "\n",
        "        return xx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTiAQ25E18Ps"
      },
      "source": [
        "\n",
        "test_loader_args = dict(shuffle = False, batch_size = batch_size, num_workers = num_workers, pin_memory =  True) \n",
        "\n",
        "dataset = load_test(test,offset, context )\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset,**test_loader_args)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aJeACrGOrtH"
      },
      "source": [
        "\n",
        "preds_total = []\n",
        "model.cuda()\n",
        "with torch.no_grad():\n",
        "  for X_test in dataloader_test:\n",
        "    X_test = X_test.to(device='cuda')\n",
        "    y_hat = model(X_test.view(X_test.size(0), -1).float())\n",
        "    \n",
        "    y_hat = y_hat.cpu()\n",
        "    y_hat = y_hat.detach().numpy()\n",
        "    \n",
        "    preds = np.argmax(y_hat, axis = 1)\n",
        "    preds = preds.reshape(-1,1)\n",
        "    preds_total.append(preds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R58GKZHpKTow"
      },
      "source": [
        "preds_final = []\n",
        "for i in preds_total:\n",
        "  for t in i:\n",
        "    preds_final.append(int(t))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R5cWkmRFOt1"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'id':np.arange(len(preds_final)), \"label\":preds_final})\n",
        "df.to_csv(r\"propose_prediction.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeerlCSjFcYd",
        "outputId": "0926e85c-387e-4357-8571-1d1180d0745e"
      },
      "source": [
        "!kaggle competitions submit -c 11785-spring2021-hw1p2 -f propose_prediction.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 15.5M/15.5M [00:05<00:00, 3.23MB/s]\n",
            "Successfully submitted to 11785-Spring2021-Hw1P2"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}