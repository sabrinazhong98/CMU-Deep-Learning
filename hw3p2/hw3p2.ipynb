{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw3p2final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg7Xzth5WtOn"
      },
      "source": [
        "# Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke7la_R2YYHC"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YROo59hm1xKN"
      },
      "source": [
        "CUDA_VISIBLE_DEVICES=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQoDVatZRlbU"
      },
      "source": [
        "dev = np.load('dev.npy', allow_pickle=True)\n",
        "dev_labels = np.load('dev_labels.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gyayEX0dFIKD"
      },
      "source": [
        "train = np.load('train.npy', allow_pickle = True)\n",
        "train_labels = np.load('train_labels.npy',allow_pickle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1XH_0e7El_2U"
      },
      "source": [
        "class Dataset_train(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = np.array(X)\n",
        "    self.Y = np.asarray(Y)\n",
        "    self.length = len(self.X)\n",
        "    \n",
        "  def __len__(self):\n",
        "      \n",
        "    return self.length\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    xx = torch.from_numpy(self.X[index])\n",
        "    yy = torch.tensor(self.Y[index])\n",
        "     \n",
        "    return xx ,yy  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4pK0Vu0cYM5N"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "  \n",
        "  sorted_batch = batch #sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "  sequences = [x[0] for x in sorted_batch]\n",
        "  labels = [x[1] for x in sorted_batch]\n",
        "  sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
        "  labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "  seq_lengths = torch.LongTensor([len(x) for x in sequences])\n",
        "  label_lengths = torch.LongTensor([len(x) for x in labels])\n",
        "\n",
        "  return sequences_padded, labels_padded,seq_lengths, label_lengths\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pm16UKXCJxMU"
      },
      "source": [
        "dataset = Dataset_train(train, train_labels)\n",
        "train_loader_args = dict(shuffle = True, batch_size = 64, num_workers = 0, collate_fn = pad_sequences, pin_memory = True) \n",
        "train = torch.utils.data.DataLoader(dataset,**train_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-KGFpEONR01j"
      },
      "source": [
        "dataset = Dataset_train(dev, dev_labels)\n",
        "dev_loader_args = dict(shuffle = False, batch_size = 64, num_workers = 0, collate_fn = pad_sequences, pin_memory = True) \n",
        "validation = torch.utils.data.DataLoader(dataset,**dev_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMZnEkQh_Ofe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uSp6-56q__wX"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "class lstmModel(nn.Module):\n",
        "    def __init__(self, hidden_size,kernel=2,nlayers=4, out_size=42, in_size=40):\n",
        "        super(lstmModel, self).__init__()\n",
        "        self.nlayers = nlayers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.in_size = in_size\n",
        "        self.out_size = out_size\n",
        "        \n",
        "        self.kernel = kernel\n",
        "\n",
        "        self.cnns = torch.nn.Sequential(\n",
        "            nn.Conv1d(self.in_size, self.hidden_size, kernel_size = self.kernel, stride = 1,padding=0, bias=False),\n",
        "            nn.BatchNorm1d(self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(self.hidden_size, self.hidden_size, kernel_size=1 , padding=0, bias=False),\n",
        "            nn.BatchNorm1d(self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "           )\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.hidden_size,hidden_size=self.hidden_size, num_layers=self.nlayers,bias=True, batch_first=True,\n",
        "                            dropout=0.4, bidirectional=True)\n",
        "\n",
        "        self.hidden2label = torch.nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2, self.hidden_size*4),\n",
        "            nn.Linear(self.hidden_size*4, self.hidden_size*2),\n",
        "            nn.Linear(self.hidden_size*2, self.out_size))\n",
        "        \n",
        "    def forward(self, x, length):   # x dim (batch, len, insize)\n",
        "        batch, lens, insize = x.shape\n",
        "\n",
        "        x = x.reshape(batch, insize,lens ) # batch, insize, len\n",
        "\n",
        "        x = self.cnns(x)       \n",
        "\n",
        "        x = x.permute(2, 0, 1)      # insize, len, batch \n",
        "  \n",
        "        length = (length- self.kernel)//1 +1\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, length, enforce_sorted=False)\n",
        "\n",
        "\n",
        "        out_packed = self.lstm(x_packed)[0]\n",
        "        out = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)[0] \n",
        "        \n",
        "        out = self.hidden2label(out).log_softmax(2) \n",
        "\n",
        "        out = out.permute(1, 0, 2) \n",
        "        \n",
        "        return out, length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UiJj8X9xdGy"
      },
      "source": [
        "# training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVQtqXCKPV15"
      },
      "source": [
        "!pip install Levenshtein\n",
        "import Levenshtein as lev\n",
        "import numpy as np\n",
        "from phoneme_list import  N_PHONEMES, PHONEME_LIST, PHONEME_MAP\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install .\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "import os\n",
        "\n",
        "def levdistance(preds, target):\n",
        "  distance = []\n",
        "  for s in range(len(preds)):\n",
        "    distance.append(lev.distance(preds[s],target[s]))\n",
        "  return np.mean(distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ra6Dt4Codi-D"
      },
      "source": [
        "def training(epoch, model, dataloader, val):\n",
        "  for epoch in range(numEpochs):\n",
        "\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    correct = 0\n",
        "      \n",
        "    for batch_num, (x, y, seq_len, label_len) in enumerate(dataloader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "      loss = criterion(outputs, y,outlen, label_len )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "      if batch_num % 99 ==1:\n",
        "        print('train loss', avg_loss)\n",
        "\n",
        "      del x\n",
        "      del y\n",
        "      del outlen\n",
        "      del label_len\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "    print('train_epoch',epoch,avg_loss) \n",
        "\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "      dist = []\n",
        "      for batch_num, (x, y, seq_len, label_len) in enumerate(val):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "        loss = criterion(outputs, y,outlen, label_len )\n",
        "        loss += loss.item()\n",
        "      \n",
        "        decoder = CTCBeamDecoder(['$']* len(PHONEME_LIST) , beam_width=20, \n",
        "                                num_processes = os.cpu_count(), log_probs_input=True)\n",
        "        \n",
        "        probs = outputs.transpose(0,1)\n",
        "\n",
        "        out, _, _, out_lens = decoder.decode(probs,outlen)\n",
        "        preds = []\n",
        "        target = []\n",
        "        \n",
        "        for i in range(len(x)):\n",
        "          best_seq = out[i, 0, :out_lens[i,0]]\n",
        "          preds.append(''.join([PHONEME_MAP[i] for i in out[i,0,:out_lens[i,0]]]))\n",
        "          target.append(''.join([PHONEME_MAP[i] for i in y[i,:out_lens[i,0]]]))\n",
        "       \n",
        "          dist.append(levdistance(preds, target))\n",
        "          #print(dist[-1])\n",
        "\n",
        "\n",
        "        del x\n",
        "        del y\n",
        "        del label_len\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "      print('test epoch',epoch,loss, np.mean(dist))\n",
        "      scheduler.step(loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6xs_orMPf0L"
      },
      "source": [
        "import tensorflow as tf\n",
        "layer = [4]\n",
        "for l in layer:\n",
        "  hidden = 256\n",
        "  learningRate = 2e-3\n",
        "  numEpochs = 30\n",
        "    \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  #model = torch.load('dist_12')\n",
        "  model = lstmModel(hidden)\n",
        "\n",
        "  model = model.cuda()\n",
        "  weightDecay = 5e-5\n",
        "\n",
        "  criterion = nn.CTCLoss()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate,weight_decay=weightDecay)\n",
        "  scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.5,3)\n",
        "\n",
        "  training(numEpochs, model, train,validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OZOCMkYyfP"
      },
      "source": [
        "# test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvtQfA0kaFmP",
        "outputId": "0afad88c-feff-4be3-a11e-9f53c502d4e0"
      },
      "source": [
        "del train\n",
        "del validation\n",
        "!unzip test.npy.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  test.npy.zip\n",
            "replace test.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrG0pDLaSuD"
      },
      "source": [
        "test = np.load('test.npy', allow_pickle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOP2hrnvaSuO"
      },
      "source": [
        "class Dataset_test(torch.utils.data.Dataset):\n",
        "  def __init__(self, X):\n",
        "    self.X = np.array(X)\n",
        "   \n",
        "    self.length = len(self.X)\n",
        "    self.Y = np.zeros(self.length)\n",
        "    \n",
        "  def __len__(self):\n",
        "      \n",
        "    return self.length\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "  \n",
        "    xx = torch.from_numpy(self.X[index])\n",
        "    yy = torch.from_numpy(self.X[index])\n",
        "     \n",
        "    return xx, yy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_aE6YWaSuO"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "  sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "  sequences = [x[0] for x in sorted_batch]\n",
        "  labels = [x[1] for x in sorted_batch]\n",
        "  sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
        "  labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "  seq_lengths = torch.LongTensor([len(x) for x in sequences])\n",
        "  label_lengths = torch.LongTensor([len(x) for x in labels])\n",
        "\n",
        "  return sequences_padded, labels_padded,seq_lengths, label_lengths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gTosRZsaSuP"
      },
      "source": [
        "dataset = Dataset_test(test)\n",
        "test_loader_args = dict(shuffle = False, batch_size = 64, num_workers = 0, collate_fn = pad_sequences) \n",
        "test = torch.utils.data.DataLoader(dataset,**test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSi2yuDDPjA1"
      },
      "source": [
        "\n",
        "preds = []\n",
        "\n",
        "for batch_num, (x, y, seq_len,label_len) in enumerate(test):\n",
        "  x = x.to(device)\n",
        "\n",
        "  outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "  decoder = CTCBeamDecoder(['$']* len(PHONEME_LIST) , beam_width=20, \n",
        "                          num_processes = os.cpu_count(), log_probs_input=True)\n",
        "\n",
        "  probs = outputs.transpose(0,1)\n",
        "\n",
        "  out, _, _, out_lens = decoder.decode(probs,outlen)\n",
        "\n",
        "  \n",
        "\n",
        "  for i in range(len(x)):\n",
        "    pmap = []\n",
        "    best_seq = out[i, 0, :out_lens[i,0]]\n",
        "    \n",
        "    for k in best_seq:\n",
        "      pmap.append(PHONEME_MAP[k])\n",
        "    preds.append(''.join(pmap))\n",
        " \n",
        "  print(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R5cWkmRFOt1"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'id':np.arange(len(preds)), \"label\":preds})\n",
        "df.to_csv(r\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeerlCSjFcYd",
        "outputId": "526e61ea-cfb1-44f6-e175-a7739d323a9b"
      },
      "source": [
        "!kaggle competitions submit -c 11785-spring2021-hw3p2-slacklate -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 203k/203k [00:02<00:00, 79.4kB/s]\n",
            "Successfully submitted to 11785 Homework 3 Part 2: Seq to Seq"
          ]
        }
      ]
    }
  ]
}