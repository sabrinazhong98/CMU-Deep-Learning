{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3p2final.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6m2eIB_WjuK"
      },
      "source": [
        "# Set up\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku1xpW9TQYcx",
        "outputId": "64f0bf6f-ae45-45a4-9157-98175fcb2188"
      },
      "source": [
        "#connect to gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive\n",
        "#%cd ../..\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esgd15775IjP",
        "outputId": "72f58252-d57a-4a33-efd0-0fdd7a295d77"
      },
      "source": [
        "%cd competitions/11785-spring2021-hw3p2\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/competitions/11785-spring2021-hw3p2\n",
            "ctcdecode\texp5\t\t\tsubmission.csv\n",
            "dev_labels.npy\tpackmodel_12\t\ttest.npy\n",
            "dev.npy\t\tpackmodel_14\t\ttest.npy.zip\n",
            "dev.npy.zip\tphoneme_list.py\t\ttrain_labels.npy\n",
            "dist_12\t\tpropose_prediction.csv\ttrain_labels.npy.zip\n",
            "dist_1225\t__pycache__\t\ttrain.npy\n",
            "dist_15\t\tsample_submission.csv\ttrain.npy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg7Xzth5WtOn"
      },
      "source": [
        "# Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke7la_R2YYHC"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQoDVatZRlbU"
      },
      "source": [
        "dev = np.load('dev.npy', allow_pickle=True)\n",
        "dev_labels = np.load('dev_labels.npy',allow_pickle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyayEX0dFIKD"
      },
      "source": [
        "train = np.load('train.npy', allow_pickle = True)\n",
        "train_labels = np.load('train_labels.npy',allow_pickle = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XH_0e7El_2U"
      },
      "source": [
        "class Dataset_train(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = np.array(X)\n",
        "    self.Y = np.asarray(Y)\n",
        "    self.length = len(self.X)\n",
        "    \n",
        "  def __len__(self):\n",
        "      \n",
        "    return self.length\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    xx = torch.from_numpy(self.X[index])\n",
        "    yy = torch.tensor(self.Y[index])\n",
        "     \n",
        "    return xx ,yy  \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pK0Vu0cYM5N"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "  \n",
        "  sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "  sequences = [x[0] for x in sorted_batch]\n",
        "  labels = [x[1] for x in sorted_batch]\n",
        "  sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
        "  labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "  seq_lengths = torch.LongTensor([len(x) for x in sequences])\n",
        "  label_lengths = torch.LongTensor([len(x) for x in labels])\n",
        "\n",
        "  return sequences_padded, labels_padded,seq_lengths, label_lengths\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm16UKXCJxMU"
      },
      "source": [
        "dataset = Dataset_train(train, train_labels)\n",
        "train_loader_args = dict(shuffle = True, batch_size = 64, num_workers = 0, collate_fn = pad_sequences, pin_memory = True) \n",
        "train = torch.utils.data.DataLoader(dataset,**train_loader_args)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KGFpEONR01j"
      },
      "source": [
        "dataset = Dataset_train(dev, dev_labels)\n",
        "dev_loader_args = dict(shuffle = False, batch_size = 64, num_workers = 0, collate_fn = pad_sequences, pin_memory = True) \n",
        "validation = torch.utils.data.DataLoader(dataset,**dev_loader_args)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMZnEkQh_Ofe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSp6-56q__wX"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "class lstmModel(nn.Module):\n",
        "    def __init__(self, hidden_size,kernel=2,nlayers=4, out_size=42, in_size=40):\n",
        "        super(lstmModel, self).__init__()\n",
        "        self.nlayers = nlayers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.in_size = in_size\n",
        "        self.out_size = out_size\n",
        "        \n",
        "        self.kernel = kernel\n",
        "\n",
        "        self.cnns = torch.nn.Sequential(\n",
        "            nn.Conv1d(self.in_size, self.hidden_size, kernel_size = self.kernel, stride = 1,padding=0, bias=False),\n",
        "            nn.BatchNorm1d(self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(self.hidden_size, self.hidden_size, kernel_size=1 , padding=0, bias=False),\n",
        "            nn.BatchNorm1d(self.hidden_size),\n",
        "            nn.ReLU(),\n",
        "           )\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.hidden_size,hidden_size=self.hidden_size, num_layers=self.nlayers,bias=True, batch_first=True,\n",
        "                            dropout=0.6, bidirectional=True)\n",
        "\n",
        "        self.hidden2label = torch.nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2, self.hidden_size*4),\n",
        "            nn.Linear(self.hidden_size*4, self.hidden_size*2),\n",
        "            nn.Linear(self.hidden_size*2, self.out_size))\n",
        "        \n",
        "    def forward(self, x, length):   # x dim (batch, len, insize)\n",
        "        batch, lens, insize = x.shape\n",
        "\n",
        "        x = x.reshape(batch, insize,lens ) # batch, insize, len\n",
        "\n",
        "        x = self.cnns(x)       \n",
        "\n",
        "        x = x.permute(2, 0, 1)      # insize, len, batch \n",
        "  \n",
        "        length = (length- self.kernel)//1 +1\n",
        "        x_packed = nn.utils.rnn.pack_padded_sequence(x, length, enforce_sorted=False)\n",
        "\n",
        "\n",
        "        out_packed = self.lstm(x_packed)[0]\n",
        "        out = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)[0] \n",
        "        \n",
        "        out = self.hidden2label(out).log_softmax(2) \n",
        "\n",
        "        out = out.permute(1, 0, 2) \n",
        "        \n",
        "        return out, length"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UiJj8X9xdGy"
      },
      "source": [
        "# training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS5X7I0zRZ1_",
        "outputId": "50553cc2-5395-49f2-c53c-51ff7b7ff460"
      },
      "source": [
        "!pip install Levenshtein\n",
        "import Levenshtein as lev\n",
        "import numpy as np\n",
        "from phoneme_list import  N_PHONEMES, PHONEME_LIST, PHONEME_MAP\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install .\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "import os\n",
        "\n",
        "def levdistance(preds, target):\n",
        "  distance = []\n",
        "  for s in range(len(preds)):\n",
        "    distance.append(lev.distance(preds[s],target[s]))\n",
        "  return np.mean(distance)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/41/ff25ae28c972a63abde29cd5cea7c648ae0e16b334693cede0522e66dd68/levenshtein-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 102kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 122kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Levenshtein) (56.0.0)\n",
            "Installing collected packages: Levenshtein\n",
            "Successfully installed Levenshtein-0.12.0\n",
            "fatal: destination path 'ctcdecode' already exists and is not an empty directory.\n",
            "Processing /content/gdrive/My Drive/competitions/11785-spring2021-hw3p2/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp37-cp37m-linux_x86_64.whl size=12854658 sha256=82594263b2dcb1c252127beee15c9fbf6733542e3a3a49c68fe9fcf5e111766f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6owdj9ht/wheels/18/06/a5/b23a52e831b0ff241412db08bb39295d904763c1148ebe64f7\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YROo59hm1xKN"
      },
      "source": [
        "CUDA_VISIBLE_DEVICES=0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra6Dt4Codi-D"
      },
      "source": [
        "def training(epoch, model, dataloader, val):\n",
        "  for epoch in range(numEpochs):\n",
        "\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    correct = 0\n",
        "      \n",
        "    for batch_num, (x, y, seq_len, label_len) in enumerate(dataloader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "      loss = criterion(outputs, y,outlen, label_len )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "\n",
        "      del x\n",
        "      del y\n",
        "      del outlen\n",
        "      del label_len\n",
        "      torch.cuda.empty_cache()\n",
        "      \n",
        "    print('train_epoch',epoch,avg_loss) \n",
        "\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "      dist = []\n",
        "      for batch_num, (x, y, seq_len, label_len) in enumerate(val):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "        loss = criterion(outputs, y,outlen, label_len )\n",
        "        loss += loss.item()\n",
        "          \n",
        "        del x\n",
        "        del y\n",
        "        del label_len\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "      print('test epoch',epoch,loss)\n",
        "      scheduler.step(loss)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "KnAFS16NnyyB",
        "outputId": "baf724f9-02a8-44d6-d598-2bca4d47dc53"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "layer = [4]\n",
        "for l in layer:\n",
        "  hidden = 256\n",
        "  learningRate = 2e-3\n",
        "  numEpochs = 30\n",
        "    \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  model = lstmModel(hidden)\n",
        "\n",
        "  model = model.cuda()\n",
        "  weightDecay = 5e-6\n",
        "\n",
        "  criterion = nn.CTCLoss()\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate,weight_decay=weightDecay)\n",
        "  scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.5,3)\n",
        "\n",
        "  training(numEpochs, model, train,validation)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_epoch 0 886.078729391098\n",
            "test epoch 0 tensor(6.8738, device='cuda:0')\n",
            "train_epoch 1 779.1616787910461\n",
            "test epoch 1 tensor(6.7573, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c6b532035542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-674848bc2878>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epoch, model, dataloader, val)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_len\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OZOCMkYyfP"
      },
      "source": [
        "# test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvtQfA0kaFmP",
        "outputId": "0afad88c-feff-4be3-a11e-9f53c502d4e0"
      },
      "source": [
        "del train\n",
        "del validation\n",
        "!unzip test.npy.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.npy.zip\n",
            "replace test.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrG0pDLaSuD"
      },
      "source": [
        "test = np.load('test.npy', allow_pickle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOP2hrnvaSuO"
      },
      "source": [
        "class Dataset_test(torch.utils.data.Dataset):\n",
        "  def __init__(self, X):\n",
        "    self.X = np.array(X)\n",
        "   \n",
        "    self.length = len(self.X)\n",
        "    self.Y = np.zeros(self.length)\n",
        "    \n",
        "  def __len__(self):\n",
        "      \n",
        "    return self.length\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "  \n",
        "    xx = torch.from_numpy(self.X[index])\n",
        "    yy = torch.from_numpy(self.X[index])\n",
        "     \n",
        "    return xx, yy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K_aE6YWaSuO"
      },
      "source": [
        "def pad_sequences(batch):\n",
        "  sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "  sequences = [x[0] for x in sorted_batch]\n",
        "  labels = [x[1] for x in sorted_batch]\n",
        "  sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
        "  labels_padded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "  seq_lengths = torch.LongTensor([len(x) for x in sequences])\n",
        "  label_lengths = torch.LongTensor([len(x) for x in labels])\n",
        "\n",
        "  return sequences_padded, labels_padded,seq_lengths, label_lengths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gTosRZsaSuP"
      },
      "source": [
        "dataset = Dataset_test(test)\n",
        "test_loader_args = dict(shuffle = False, batch_size = 64, num_workers = 0, collate_fn = pad_sequences) \n",
        "test = torch.utils.data.DataLoader(dataset,**test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "BMw8-ZQS3KKI",
        "outputId": "fe98aad4-7593-4517-f072-a185b2e2b3b7"
      },
      "source": [
        "\n",
        "preds = []\n",
        "\n",
        "for batch_num, (x, y, seq_len,label_len) in enumerate(test):\n",
        "  x = x.to(device)\n",
        "\n",
        "  outputs, outlen = model(x.float(), seq_len)\n",
        "\n",
        "  decoder = CTCBeamDecoder(['$']* len(PHONEME_LIST) , beam_width=20, \n",
        "                          num_processes = os.cpu_count(), log_probs_input=True)\n",
        "\n",
        "  probs = outputs.transpose(0,1)\n",
        "\n",
        "  out, _, _, out_lens = decoder.decode(probs,outlen)\n",
        "\n",
        "  \n",
        "\n",
        "  for i in range(len(x)):\n",
        "    pmap = []\n",
        "    best_seq = out[i, 0, :out_lens[i,0]]\n",
        "    \n",
        "    for k in best_seq:\n",
        "      pmap.append(PHONEME_MAP[k])\n",
        "    preds.append(''.join(pmap))\n",
        " \n",
        "  print(preds)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h']\n",
            "['h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h']\n",
            "['h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-85856f0485b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ctcdecode/__init__.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, probs, seq_lens)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cutoff_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutoff_top_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blank_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                           output, timesteps, scores, out_seq_len)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R5cWkmRFOt1"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'id':np.arange(len(preds)), \"label\":preds})\n",
        "df.to_csv(r\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeerlCSjFcYd",
        "outputId": "526e61ea-cfb1-44f6-e175-a7739d323a9b"
      },
      "source": [
        "!kaggle competitions submit -c 11785-spring2021-hw3p2-slacklate -f submission.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 203k/203k [00:02<00:00, 79.4kB/s]\n",
            "Successfully submitted to 11785 Homework 3 Part 2: Seq to Seq"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}